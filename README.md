# Bagging-Classifier-from-scratch

The ipynb file contains the solution to the attached Problem Statement.

It contains an implementation of Bagging Classifier from scratch.

**About Bagging Classifier:**

![image](https://user-images.githubusercontent.com/55259635/185788371-38b72698-ec50-4817-aa00-2f90a1c6a9ae.png)

Bootstrap Aggregation, or Bagging for short, is an ensemble machine learning algorithm.

Specifically, it is an ensemble of decision tree models, although the bagging technique can also be used to combine the predictions of other types of models.

As its name suggests, bootstrap aggregation is based on the idea of the “bootstrap” sample.

A bootstrap sample is a sample of a dataset with replacement. Replacement means that a sample drawn from the dataset is replaced, allowing it to be selected again and perhaps multiple times in the new sample. This means that the sample may have duplicate examples from the original dataset.

The bootstrap sampling technique is used to estimate a population statistic from a small data sample. This is achieved by drawing multiple bootstrap samples, calculating the statistic on each, and reporting the mean statistic across all samples.

You can read more about Bagging [here](https://machinelearningmastery.com/bagging-ensemble-with-python/)
